# chat GPT

## 💠주요 개념

### Generative AI
- 기존 패턴을 기반으로 오디오, 비디오, 이미지, 텍스트, 코드, 새뮬레이션 등의 새로운 콘텐츠 생성하는 인공지능 모델

### Pre-trained
- 거대 언어 모델 + 추가 학습 데이터 + 추가 강화 학습

### Transformer
- 문장 속 단어 간의 관계 추적해 맥락과 의미 학습
- 인간처럼 일관되고 연관성 높은 언어 구사하여 대화형 작업에 강점

## 💠Generative AI
- 오디오, 비디오, 이미, 텍스트, 코드, 시뮬레이션 등의 새로운 콘텐츠 생성하는 인공지능 모델
- 최근 언어 및 이미지 분석에서 큰 파급력 보임

## 💠Transformer
- 문장의 맥락을 효과적으로 이해하고 처리 -> attention(지도학습) 메커니즘 (알고리즘 계산법)
- programming architecture 중 하나 (neural network architecture)

### Transformer 주요 개념
- self-attention(자율학습) 메커니즘
    - 입력 데이터 간 관계와 중요도 계싼
- 병렬 처리 가능
    - RNN과 달리 순차 처리 필요 없어 속도 빠름
- 스케일링 가능
    - 대규모 데이터 및 파라미터로 확장 가능
- GPT 모델은 특히 Transformer의 디코더 부분만을 사용
    - 번역기 구조 : encoder ---- decoder
> ### ✅ attention 메커니즘
> - AI가 데이터 맥락과 중요도를 이해하도록 돕는 필수 기술
> - 입력 데이터 각 요소가 출력에 얼마나 중요한지 중요도(weight)를 계산하는 기법
> - "중요한 것에 집중한다"는 아이디어 바탕으로 설계됨

